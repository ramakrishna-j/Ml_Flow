{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Using cached mlflow-2.1.1-py3-none-any.whl (16.7 MB)\n",
      "Collecting databricks-cli<1,>=0.8.7\n",
      "  Using cached databricks-cli-0.17.4.tar.gz (82 kB)\n",
      "Collecting gitpython<4,>=2.1.0\n",
      "  Using cached GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
      "Requirement already satisfied: pandas<2 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (1.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (2.27.1)\n",
      "Collecting docker<7,>=4.0.0\n",
      "  Using cached docker-6.0.1-py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (6.0)\n",
      "Collecting Flask<3\n",
      "  Using cached Flask-2.2.2-py3-none-any.whl (101 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (8.1.3)\n",
      "Requirement already satisfied: entrypoints<1 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (0.4)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (3.3.6)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (3.3.2)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (3.0.3)\n",
      "Collecting alembic<2\n",
      "  Using cached alembic-1.9.2-py3-none-any.whl (210 kB)\n",
      "Collecting querystring-parser<2\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (1.5.2)\n",
      "Collecting shap<1,>=0.40\n",
      "  Downloading shap-0.41.0-cp38-cp38-win_amd64.whl (435 kB)\n",
      "Requirement already satisfied: pytz<2023 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (2022.1)\n",
      "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (1.4.39)\n",
      "Collecting pyarrow<11,>=4.0.0\n",
      "  Downloading pyarrow-10.0.1-cp38-cp38-win_amd64.whl (20.3 MB)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (1.19.1)\n",
      "Collecting waitress<3\n",
      "  Using cached waitress-2.1.2-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<6,>=3.7.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (4.11.3)\n",
      "Requirement already satisfied: packaging<23 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (21.3)\n",
      "Collecting protobuf<5,>=3.12.0\n",
      "  Downloading protobuf-4.21.12-cp38-cp38-win_amd64.whl (527 kB)\n",
      "Collecting sqlparse<1,>=0.4.0\n",
      "  Using cached sqlparse-0.4.3-py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: cloudpickle<3 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from mlflow) (2.0.0)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from alembic<2->mlflow) (5.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from click<9,>=7.0->mlflow) (0.4.4)\n",
      "Collecting pyjwt>=1.7.0\n",
      "  Using cached PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
      "Collecting oauthlib>=3.1.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.8.10)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
      "Collecting pywin32>=304\n",
      "  Downloading pywin32-305-cp38-cp38-win_amd64.whl (12.3 MB)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from docker<7,>=4.0.0->mlflow) (1.3.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from docker<7,>=4.0.0->mlflow) (1.26.9)\n",
      "Collecting Werkzeug>=2.2.2\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from Flask<3->mlflow) (2.1.2)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow) (3.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (2.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from matplotlib<4->mlflow) (3.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.2)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from matplotlib<4->mlflow) (2022.6.15)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from matplotlib<4->mlflow) (9.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (2.0.12)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from scikit-learn<2->mlflow) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from scikit-learn<2->mlflow) (1.1.0)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from shap<1,>=0.40->mlflow) (4.48.2)\n",
      "Requirement already satisfied: numba in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from shap<1,>=0.40->mlflow) (0.55.1)\n",
      "Collecting slicer==0.0.7\n",
      "  Using cached slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from sqlalchemy<2,>=1.4.0->mlflow) (1.1.2)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from numba->shap<1,>=0.40->mlflow) (0.38.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ramakrishna.j\\miniconda3\\envs\\ta-tigerml\\lib\\site-packages (from numba->shap<1,>=0.40->mlflow) (61.2.0)\n",
      "Building wheels for collected packages: databricks-cli\n",
      "  Building wheel for databricks-cli (setup.py): started\n",
      "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.17.4-py3-none-any.whl size=142889 sha256=2ee8053c572c27108043d6458fb021fcb01ca885ec7c4b3e4f054f7b7ce9a01a\n",
      "  Stored in directory: c:\\users\\ramakrishna.j\\appdata\\local\\pip\\cache\\wheels\\48\\7c\\6e\\4bf2c1748c7ecf994ca951591de81674ed6bf633e1e337d873\n",
      "Successfully built databricks-cli\n",
      "Installing collected packages: Werkzeug, slicer, pywin32, pyjwt, oauthlib, Mako, gitdb, waitress, sqlparse, shap, querystring-parser, pyarrow, protobuf, gitpython, Flask, docker, databricks-cli, alembic, mlflow\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 2.1.2\n",
      "    Uninstalling Werkzeug-2.1.2:\n",
      "      Successfully uninstalled Werkzeug-2.1.2\n",
      "  Attempting uninstall: pywin32\n",
      "    Found existing installation: pywin32 227\n",
      "    Uninstalling pywin32-227:\n",
      "      Successfully uninstalled pywin32-227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\ramakrishna.j\\\\Miniconda3\\\\envs\\\\ta-tigerml\\\\Lib\\\\site-packages\\\\~-win32_system32\\\\pythoncom38.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlflow'"
     ]
    }
   ],
   "source": [
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT =\"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_housing_data(housing_url=HOUSING_URL,housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data(housing_url=HOUSING_URL,housing_path=HOUSING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data(housing_path=HOUSING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Mlflow server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_server_uri = \"http://localhost:5000\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:5000'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/16 14:13:03 INFO mlflow.tracking.fluent: Experiment with name 'ElasticNet_house' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlruns/158930113435695454', creation_time=1673858589900, experiment_id='158930113435695454', last_update_time=1673858589900, lifecycle_stage='active', name='ElasticNet_house', tags={}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"ElasticNet_house\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mlflow tracking parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:,households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household,population_per_household,bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household,population_per_household]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                ('attribs_adder', CombinedAttributesAdder()),('std_scaler', StandardScaler()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    # compute relevant metrics\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(alpha=0.5, l1_ratio=0.5):\n",
    "    # train a model with given parameters\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "    \n",
    "    housing = load_housing_data(housing_path=HOUSING_PATH)\n",
    "    train_set, test_set = train_test_split(housing, test_size=0.2,random_state=42)\n",
    "    \n",
    "    with mlflow.start_run(run_name='Main') as parent_run:\n",
    "        mlflow.log_param(\"Main\", \"yes\")\n",
    "        split = StratifiedShuffleSplit(n_splits=1, test_size=0.2,random_state=42)\n",
    "        \n",
    "        with mlflow.start_run(run_name='Data_Preparation', nested=True) as child_run:\n",
    "            mlflow.log_param(\"Data Preparayion\", \"yes\")\n",
    "    \n",
    "            housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],bins=[0., 1.5, 3.0, 4.5, 6., np.inf],labels=[1, 2, 3, 4, 5])\n",
    "    \n",
    "            for train_index, test_index in split.split(housing,housing[\"income_cat\"]):\n",
    "                strat_train_set = housing.loc[train_index]\n",
    "                strat_test_set = housing.loc[test_index]\n",
    "        \n",
    "            for set_ in (strat_train_set, strat_test_set):\n",
    "                set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "        \n",
    "            housing = strat_train_set.copy()\n",
    "    \n",
    "            housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "            housing[\"bedrooms_per_room\"] =housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "            housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]\n",
    "    \n",
    "            housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "            housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "    \n",
    "            median = housing[\"total_bedrooms\"].median() # option 3\n",
    "            housing[\"total_bedrooms\"].fillna(median, inplace=True)\n",
    "    \n",
    "    \n",
    "            imputer = SimpleImputer(strategy=\"median\")\n",
    "    \n",
    "            housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "    \n",
    "            imputer.fit(housing_num)\n",
    "    \n",
    "            X = imputer.transform(housing_num)\n",
    "    \n",
    "            housing_tr = pd.DataFrame(X, columns=housing_num.columns,index=housing_num.index)\n",
    "    \n",
    "            housing_cat = housing[[\"ocean_proximity\"]]\n",
    "    \n",
    "            ordinal_encoder = OrdinalEncoder()\n",
    "            housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "    \n",
    "            cat_encoder = OneHotEncoder()\n",
    "            housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "    \n",
    "    \n",
    "    \n",
    "            attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "            housing_extra_attribs = attr_adder.transform(housing.values)\n",
    "    \n",
    "            housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "    \n",
    "            num_attribs = list(housing_num)\n",
    "            cat_attribs = [\"ocean_proximity\"]\n",
    "    \n",
    "            full_pipeline = ColumnTransformer([(\"num\", num_pipeline, num_attribs),\n",
    "                (\"cat\", OneHotEncoder(), cat_attribs),])\n",
    "        \n",
    "            housing_prepared = full_pipeline.fit_transform(housing)\n",
    "            \n",
    "        with mlflow.start_run(run_name='Model_Training', nested=True) as child_run:\n",
    "            mlflow.log_param(\"Model Training\", \"yes\")\n",
    "    \n",
    "            lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "            lr.fit(housing_prepared, housing_labels)\n",
    "    \n",
    "            predicted_qualities = lr.predict(housing_prepared)\n",
    "            (rmse, mae, r2) = eval_metrics(housing_labels, predicted_qualities)\n",
    "        \n",
    "        with mlflow.start_run(run_name='Model_Performance', nested=True) as child_run:\n",
    "            mlflow.log_param(\"Model Performance\", \"yes\")\n",
    "            print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "            print(\"  RMSE: %s\" % rmse)\n",
    "            print(\"  MAE: %s\" % mae)\n",
    "            print(\"  R2: %s\" % r2)\n",
    "    \n",
    "            mlflow.log_param(key=\"alpha\", value=alpha)\n",
    "            mlflow.log_param(key=\"l1_ratio\", value=l1_ratio)\n",
    "            mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "            mlflow.log_metrics({\"mae\": mae, \"r2\": r2})\n",
    "            mlflow.log_artifact('datasets')\n",
    "            print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "            mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.500000, l1_ratio=0.500000):\n",
      "  RMSE: 73689.95546046467\n",
      "  MAE: 54624.63812598483\n",
      "  R2: 0.59433603239391\n",
      "Save to: mlruns/158930113435695454/bb7df96da8d149aeadfb6bc0b3eb2a8f/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(0.5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.200000, l1_ratio=0.200000):\n",
      "  RMSE: 71734.82432989801\n",
      "  MAE: 52579.03875426437\n",
      "  R2: 0.6155765038209369\n",
      "Save to: mlruns/158930113435695454/0a1dc352e2e3414f8cb915f8bf4c4744/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(0.2, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
